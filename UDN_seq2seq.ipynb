{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchtext.data import Field, TabularDataset, BucketIterator\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.2\n"
     ]
    }
   ],
   "source": [
    "print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Stopword & Nonalphanumeric Removal, Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_txt_one(path, store_dict, strornot):\n",
    "    with open(path,'r',encoding='UTF-8') as file :\n",
    "        for line in tqdm(file) :\n",
    "            new = line.strip()\n",
    "            if not strornot:\n",
    "                store_dict[int(new)] = 'y'\n",
    "            else:\n",
    "                store_dict[new] = 'y'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6976583428a45f7828ba6dd7a1bb434",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "stopwords = {}\n",
    "read_txt_one('./tra_chn_stpwords.txt', stopwords, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(row):\n",
    "    new_row = []\n",
    "    for word in row.split(' '):\n",
    "        try:\n",
    "            stopwords[word]\n",
    "        except:\n",
    "            new_row.append(word)        \n",
    "    return ' '.join(new_row) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preserve_alphanumeric(row):\n",
    "    rule = re.compile(r\"[^a-zA-Z0-9\\u4e00-\\u9fa5]\")\n",
    "    row = rule.sub(' ',row)\n",
    "    row = ' '.join([word for word in row.split(' ') if word])\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('udn_train.csv', encoding = 'utf-8')[['headline_tk', 'body_tk']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline_tk</th>\n",
       "      <th>body_tk</th>\n",
       "      <th>hl_tok_stp</th>\n",
       "      <th>bd_tok_stp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>不 怕 高 持有稅 ， 囤房族 增加 逾 5千 人 擁有 逾 10 戶</td>\n",
       "      <td>各 縣 市政府 近年 陸續 調高 不 動產 稅基 ， 使地 價稅 及 房屋 稅 增加 ， 讓...</td>\n",
       "      <td>高 持有稅 囤房族 增加 逾 5千 人 擁有 逾 10 戶</td>\n",
       "      <td>高 持有稅 囤房族 增加 逾 5千 人 擁有 逾 10 戶</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MLB／ 誰 是 胡智為 ？ ， 光芒 貼心教 發音</td>\n",
       "      <td>升上 大 聯盟 後 的 台灣 小 將 胡 智為 26 日 作客 巴爾 的 摩金 鶯隊 ， 仍...</td>\n",
       "      <td>MLB 胡智為 光芒 貼心教 發音</td>\n",
       "      <td>MLB 胡智為 光芒 貼心教 發音</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>女神 陳綺貞 面前 聊 A 的 ！ 五月天 差點 變 「 五月本 」</td>\n",
       "      <td>( function ( d ,   s ,   id )   {   var   js ,...</td>\n",
       "      <td>女神 陳綺貞 面前 聊 五月天 差點 變 五月本</td>\n",
       "      <td>女神 陳綺貞 面前 聊 五月天 差點 變 五月本</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>馬來西亞 前 首相 納吉 被 控 洗錢 ， 出庭 不 認罪</td>\n",
       "      <td>馬來 西亞 前首相 納吉 （ Najib   Razak ） 涉數 十億 美元 金融 醜聞 ...</td>\n",
       "      <td>馬來西亞 前 首相 納吉 控 洗錢 出庭 認罪</td>\n",
       "      <td>馬來西亞 前 首相 納吉 控 洗錢 出庭 認罪</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>紙風車 待用券 ， 邀 新 住民 欣賞 《 諸葛 》</td>\n",
       "      <td>魔鬼 黨們 後 空翻 入場 ， 搭配 動感 的 主題 曲音樂 ， 在 舞台 上 手舞足蹈 ，...</td>\n",
       "      <td>紙風車 待用券 邀 新 住民 欣賞 諸葛</td>\n",
       "      <td>紙風車 待用券 邀 新 住民 欣賞 諸葛</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           headline_tk  \\\n",
       "0  不 怕 高 持有稅 ， 囤房族 增加 逾 5千 人 擁有 逾 10 戶   \n",
       "1           MLB／ 誰 是 胡智為 ？ ， 光芒 貼心教 發音   \n",
       "2   女神 陳綺貞 面前 聊 A 的 ！ 五月天 差點 變 「 五月本 」   \n",
       "3        馬來西亞 前 首相 納吉 被 控 洗錢 ， 出庭 不 認罪   \n",
       "4           紙風車 待用券 ， 邀 新 住民 欣賞 《 諸葛 》   \n",
       "\n",
       "                                             body_tk  \\\n",
       "0  各 縣 市政府 近年 陸續 調高 不 動產 稅基 ， 使地 價稅 及 房屋 稅 增加 ， 讓...   \n",
       "1  升上 大 聯盟 後 的 台灣 小 將 胡 智為 26 日 作客 巴爾 的 摩金 鶯隊 ， 仍...   \n",
       "2  ( function ( d ,   s ,   id )   {   var   js ,...   \n",
       "3  馬來 西亞 前首相 納吉 （ Najib   Razak ） 涉數 十億 美元 金融 醜聞 ...   \n",
       "4  魔鬼 黨們 後 空翻 入場 ， 搭配 動感 的 主題 曲音樂 ， 在 舞台 上 手舞足蹈 ，...   \n",
       "\n",
       "                      hl_tok_stp                     bd_tok_stp  \n",
       "0  高 持有稅 囤房族 增加 逾 5千 人 擁有 逾 10 戶  高 持有稅 囤房族 增加 逾 5千 人 擁有 逾 10 戶  \n",
       "1              MLB 胡智為 光芒 貼心教 發音              MLB 胡智為 光芒 貼心教 發音  \n",
       "2       女神 陳綺貞 面前 聊 五月天 差點 變 五月本       女神 陳綺貞 面前 聊 五月天 差點 變 五月本  \n",
       "3        馬來西亞 前 首相 納吉 控 洗錢 出庭 認罪        馬來西亞 前 首相 納吉 控 洗錢 出庭 認罪  \n",
       "4           紙風車 待用券 邀 新 住民 欣賞 諸葛           紙風車 待用券 邀 新 住民 欣賞 諸葛  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['hl_tok_stp']=data['headline_tk'].apply(preserve_alphanumeric)\n",
    "data['bd_tok_stp']=data['body_tk'].apply(preserve_alphanumeric)\n",
    "data['hl_tok_stp']=data['hl_tok_stp'].apply(remove_stopwords)\n",
    "data['bd_tok_stp']=data['bd_tok_stp'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid = np.random.choice([i for i in range(len(data))],size = 49297, replace = False)\n",
    "train = [i for i in range(len(data)) if i not in valid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[train,:].to_csv('udn_train_new.csv', index = False)\n",
    "data.loc[valid,:].to_csv('udn_valid_new.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('udn_test.csv', encoding = 'utf-8')[['headline_tk', 'body_tk']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['hl_tok_stp']=data['headline_tk'].apply(preserve_alphanumeric)\n",
    "data['bd_tok_stp']=data['body_tk'].apply(preserve_alphanumeric)\n",
    "data['hl_tok_stp']=data['hl_tok_stp'].apply(remove_stopwords)\n",
    "data['bd_tok_stp']=data['bd_tok_stp'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('udn_test_new.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Character Based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv('udn_train_new.csv', encoding = 'utf-8')[['hl_tok_stp', 'bd_tok_stp']]\n",
    "data_valid = pd.read_csv('udn_valid_new.csv', encoding = 'utf-8')[['hl_tok_stp', 'bd_tok_stp']]\n",
    "data_test = pd.read_csv('udn_test_new.csv', encoding = 'utf-8')[['hl_tok_stp', 'bd_tok_stp']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def char_based(row):\n",
    "    try:\n",
    "        return ' '.join(list(''.join(row.split(' '))))\n",
    "    except:\n",
    "        return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train['hl_tok_stp'] = data_train['hl_tok_stp'].apply(char_based)\n",
    "data_train['bd_tok_stp'] = data_train['bd_tok_stp'].apply(char_based)\n",
    "\n",
    "data_valid['hl_tok_stp'] = data_valid['hl_tok_stp'].apply(char_based)\n",
    "data_valid['bd_tok_stp'] = data_valid['bd_tok_stp'].apply(char_based)\n",
    "\n",
    "data_test['hl_tok_stp'] = data_test['hl_tok_stp'].apply(char_based)\n",
    "data_test['bd_tok_stp'] = data_test['bd_tok_stp'].apply(char_based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_new.to_csv('udn_train_char.csv', index = False)\n",
    "data_valid.to_csv('udn_valid_char.csv', index = False)\n",
    "data_test.to_csv('udn_test_char.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data_train, data_valid, data_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cut news to 400 characters ( median length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv('udn_train_char.csv', encoding = 'utf-8')\n",
    "data_valid = pd.read_csv('udn_valid_char.csv', encoding = 'utf-8')\n",
    "data_test = pd.read_csv('udn_test_new.csv', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_to_median(row):\n",
    "    return str(row)[:800]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train['hl_tok_stp'] = data_train['hl_tok_stp'].apply(cut_to_median)\n",
    "data_train['bd_tok_stp'] = data_train['bd_tok_stp'].apply(cut_to_median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_valid['hl_tok_stp'] = data_valid['hl_tok_stp'].apply(cut_to_median)\n",
    "data_valid['bd_tok_stp'] = data_valid['bd_tok_stp'].apply(cut_to_median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test['hl_tok_stp'] = data_test['hl_tok_stp'].apply(cut_to_median)\n",
    "data_test['bd_tok_stp'] = data_test['bd_tok_stp'].apply(cut_to_median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.to_csv('udn_train_char_med.csv', index = False)\n",
    "data_valid.to_csv('udn_valid_char_med.csv', index = False)\n",
    "data_test.to_csv('udn_test_char_med.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "800"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_train.loc[5,:]['bd_tok_stp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize = lambda x: x.split(' ')\n",
    "SRC = Field(tokenize = tokenize, \n",
    "            init_token = '<sos>', \n",
    "            eos_token = '<eos>')\n",
    "\n",
    "TRG = Field(tokenize = tokenize, \n",
    "            init_token = '<sos>', \n",
    "            eos_token = '<eos>')\n",
    "\n",
    "train_data, valid_data, test_data = TabularDataset.splits(\n",
    "                                    path = './',\n",
    "                                    train = 'udn_train_char.csv',\n",
    "                                    validation = 'udn_valid_char.csv',\n",
    "                                    test = 'udn_test_char.csv',\n",
    "                                    format = 'csv',\n",
    "                                    fields = (('trg', TRG), ('src',SRC)),\n",
    "                                    skip_header = True)\n",
    "\n",
    "SRC.build_vocab(train_data, min_freq = 0)\n",
    "TRG.build_vocab(train_data, min_freq = 0)\n",
    "\n",
    "print(f\"Unique tokens in source vocabulary: {len(SRC.vocab)}\")\n",
    "print(f\"Unique tokens in target vocabulary: {len(TRG.vocab)}\")\n",
    "BATCH_SIZE = 16\n",
    "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "     batch_size = BATCH_SIZE,\n",
    "     device = device, \n",
    "     sort_within_batch = True,\n",
    "     sort_key = lambda x : len(x.src))\n",
    "     \n",
    "del train_data, valid_data\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC = Field(tokenize = tokenize, \n",
    "            init_token = '<sos>', \n",
    "            eos_token = '<eos>')\n",
    "\n",
    "TRG = Field(tokenize = tokenize, \n",
    "            init_token = '<sos>', \n",
    "            eos_token = '<eos>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, valid_data, test_data = TabularDataset.splits(\n",
    "                                    path = './',\n",
    "                                    train = 'udn_train_char.csv',\n",
    "                                    validation = 'udn_valid_char.csv',\n",
    "                                    test = 'udn_test_char.csv',\n",
    "                                    format = 'csv',\n",
    "                                    fields = (('trg', TRG), ('src',SRC)),\n",
    "                                    skip_header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC.build_vocab(train_data, min_freq = 0)\n",
    "TRG.build_vocab(train_data, min_freq = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in source vocabulary: 9232\n",
      "Unique tokens in target vocabulary: 5967\n"
     ]
    }
   ],
   "source": [
    "print(f\"Unique tokens in source vocabulary: {len(SRC.vocab)}\")\n",
    "print(f\"Unique tokens in target vocabulary: {len(TRG.vocab)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "     batch_size = BATCH_SIZE,\n",
    "     device = device, \n",
    "     sort_within_batch = True,\n",
    "     sort_key = lambda x : len(x.src))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_data, valid_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the Seq2Seq Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, hid_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        \n",
    "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout = dropout)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, src):\n",
    "        \n",
    "        #src = [src len, batch size]\n",
    "        \n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        #embedded = [src len, batch size, emb dim]\n",
    "\n",
    "        outputs, (hidden, cell) = self.rnn(embedded)\n",
    "        \n",
    "        #outputs = [src len, batch size, hid dim * n directions]\n",
    "        #hidden = [n layers * n direction, batch size, hid dim]\n",
    "        #cell = [n layers * n directions, batch size, hid dim]    \n",
    "        #outputs are always from the top hidden layer\n",
    "        \n",
    "        return hidden, cell\n",
    "    \n",
    "    def initHidden():\n",
    "        return torch.zeros(1, self.hid_dim, self.hid_dim, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, hid_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.output_dim = output_dim\n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "        \n",
    "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout = dropout)\n",
    "        \n",
    "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, input, hidden, cell):\n",
    "        \n",
    "        #input = [batch size]\n",
    "        #hidden = [n layers * n directions, batch size, hid dim]\n",
    "        #cell = [n layers * n directions, batch size, hid dim]\n",
    "        \n",
    "        #n directions in the decoder will both always be 1, therefore:\n",
    "        #hidden = [n layers, batch size, hid dim]\n",
    "        #context = [n layers, batch size, hid dim]\n",
    "        \n",
    "        input = input.unsqueeze(0)\n",
    "        #input = [1, batch size]\n",
    "\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        #embedded = [1, batch size, emb dim]\n",
    "                \n",
    "        output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n",
    "        #output = [seq len, batch size, hid dim * n directions]\n",
    "        #hidden = [n layers * n directions, batch size, hid dim]\n",
    "        #cell = [n layers * n directions, batch size, hid dim]\n",
    "        \n",
    "        #seq len and n directions will always be 1 in the decoder, therefore:\n",
    "        #output = [1, batch size, hid dim]\n",
    "        #hidden = [n layers, batch size, hid dim]\n",
    "        #cell = [n layers, batch size, hid dim]\n",
    "        \n",
    "        prediction = self.softmax(self.fc_out(output.squeeze(0)))\n",
    "        \n",
    "        #prediction = [batch size, output dim]\n",
    "        \n",
    "        \n",
    "        return prediction, hidden, cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seq2Seq "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "        \n",
    "        assert encoder.hid_dim == decoder.hid_dim, \\\n",
    "            \"Hidden dimensions of encoder and decoder must be equal!\"\n",
    "        assert encoder.n_layers == decoder.n_layers, \\\n",
    "            \"Encoder and decoder must have equal number of layers!\"\n",
    "        \n",
    "    def forward(self, src, trg, teacher_forcing_ratio = 0.5):\n",
    "        \n",
    "        #src = [src len, batch size]\n",
    "        #trg = [trg len, batch size]\n",
    "        #teacher_forcing_ratio is probability to use teacher forcing\n",
    "        #e.g. if teacher_forcing_ratio is 0.75 we use ground-truth inputs 75% of the time\n",
    "        \n",
    "        batch_size = trg.shape[1]\n",
    "        trg_len = trg.shape[0]\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "        \n",
    "        #tensor to store decoder outputs\n",
    "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
    "        \n",
    "        #last hidden state of the encoder is used as the initial hidden state of the decoder\n",
    "        encoder_hidden, encoder_cell = self.encoder(src)\n",
    "        \n",
    "        #first input to the decoder is the <sos> tokens\n",
    "        decoder_input = trg[0,:]\n",
    "        \n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoder_cell = encoder_cell\n",
    "        \n",
    "        for t in range(1, trg_len):\n",
    "            \n",
    "            #insert input token embedding, previous hidden and previous cell states\n",
    "            #receive output tensor (predictions) and new hidden and cell states\n",
    "            output, decoder_hidden, decoder_cell = self.decoder(decoder_input, decoder_hidden, decoder_cell)\n",
    "            \n",
    "            #place predictions in a tensor holding predictions for each token\n",
    "            outputs[t] = output\n",
    "            \n",
    "            #decide if we are going to use teacher forcing or not\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            \n",
    "            #get the highest predicted token from our predictions\n",
    "            top1 = output.argmax(1) \n",
    "            \n",
    "            #if teacher forcing, use actual next token as next input\n",
    "            #if not, use predicted token\n",
    "            decoder_input = trg[t] if teacher_force else top1\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Seq2Seq Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(SRC.vocab)\n",
    "OUTPUT_DIM = len(TRG.vocab)\n",
    "ENC_EMB_DIM = 128\n",
    "DEC_EMB_DIM = 128\n",
    "HID_DIM = 256\n",
    "N_LAYERS = 2\n",
    "ENC_DROPOUT = 0.5\n",
    "DEC_DROPOUT = 0.5\n",
    "\n",
    "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
    "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n",
    "\n",
    "model = Seq2Seq(enc, dec, device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(11229, 256)\n",
       "    (rnn): LSTM(256, 512, dropout=0.5)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embedding): Embedding(6205, 256)\n",
       "    (rnn): LSTM(256, 512, dropout=0.5)\n",
       "    (fc_out): Linear(in_features=512, out_features=6205, bias=True)\n",
       "    (softmax): LogSoftmax()\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        nn.init.uniform_(param.data, -0.08, 0.08)\n",
    "        \n",
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 10,800,189 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0325,  0.0669,  0.0255,  ...,  0.0019, -0.0480, -0.0583],\n",
      "        [ 0.0754,  0.0688, -0.0305,  ...,  0.0767, -0.0490,  0.0415],\n",
      "        [-0.0789,  0.0481, -0.0205,  ...,  0.0798,  0.0528, -0.0080],\n",
      "        ...,\n",
      "        [-0.0684, -0.0038, -0.0237,  ..., -0.0545,  0.0070, -0.0106],\n",
      "        [ 0.0194,  0.0226, -0.0183,  ..., -0.0392, -0.0684,  0.0670],\n",
      "        [-0.0099, -0.0335,  0.0674,  ..., -0.0003, -0.0179,  0.0753]],\n",
      "       device='cuda:0')\n",
      "tensor([[ 6.5498e-05, -4.3551e-04,  6.1081e-02,  ...,  5.8089e-02,\n",
      "          2.4228e-02,  3.2461e-02],\n",
      "        [-6.2883e-02, -3.2338e-03,  1.5267e-02,  ...,  3.1488e-02,\n",
      "          1.0186e-02, -7.8064e-02],\n",
      "        [-4.0181e-02, -1.8052e-02, -5.7386e-03,  ..., -2.6327e-02,\n",
      "          7.0339e-02,  3.5711e-02],\n",
      "        ...,\n",
      "        [ 2.0285e-03,  2.1925e-02,  6.7439e-02,  ..., -8.5020e-04,\n",
      "          2.4513e-02, -6.8367e-02],\n",
      "        [-7.4410e-02,  7.6930e-02,  6.1950e-02,  ..., -1.7178e-02,\n",
      "          2.2511e-02, -8.9298e-03],\n",
      "        [ 7.1127e-02,  1.7716e-02, -5.9226e-02,  ...,  7.1030e-02,\n",
      "          2.5745e-02, -2.0526e-02]], device='cuda:0')\n",
      "tensor([[-0.0195, -0.0206, -0.0389,  ...,  0.0306,  0.0105,  0.0141],\n",
      "        [ 0.0455, -0.0404,  0.0293,  ...,  0.0718, -0.0096, -0.0688],\n",
      "        [-0.0024,  0.0659,  0.0514,  ...,  0.0122, -0.0453, -0.0098],\n",
      "        ...,\n",
      "        [-0.0491, -0.0535, -0.0777,  ..., -0.0397, -0.0152, -0.0402],\n",
      "        [-0.0546, -0.0280, -0.0445,  ..., -0.0383, -0.0162,  0.0408],\n",
      "        [ 0.0544,  0.0474,  0.0094,  ...,  0.0231, -0.0540, -0.0062]],\n",
      "       device='cuda:0')\n",
      "tensor([-1.0841e-02, -7.8514e-02,  7.8361e-02, -2.6121e-02, -2.1120e-02,\n",
      "         3.0674e-02, -3.4268e-02,  2.1774e-03, -2.5439e-02,  1.0860e-02,\n",
      "         2.8256e-03, -6.1618e-02,  6.1709e-02,  2.1891e-02,  4.0562e-02,\n",
      "        -4.6699e-02,  7.0986e-02,  7.1014e-03, -4.0735e-02,  4.1053e-02,\n",
      "         4.4687e-02,  7.8941e-02,  1.3755e-02, -6.5334e-02, -6.6678e-02,\n",
      "        -6.7393e-02,  3.5819e-02,  1.0722e-02, -2.6139e-02,  7.9909e-02,\n",
      "         4.4329e-02,  1.0438e-02,  2.3769e-03,  5.4808e-03, -6.3107e-02,\n",
      "        -6.8702e-02, -7.3130e-02,  5.9871e-02,  1.7671e-02,  6.4663e-02,\n",
      "        -6.8222e-02, -1.3303e-02, -7.9262e-02, -6.7773e-02,  4.1695e-02,\n",
      "         1.4960e-02, -4.6664e-02,  1.1465e-02,  6.5375e-02,  7.9474e-02,\n",
      "        -2.4179e-02, -4.7310e-02, -2.8602e-03,  2.1893e-03, -7.5488e-02,\n",
      "         6.4104e-02,  5.9521e-02, -2.2626e-03, -9.3868e-03, -2.5124e-02,\n",
      "        -2.6678e-02, -4.2228e-02, -4.9947e-02,  7.9808e-02,  4.4092e-03,\n",
      "         1.1275e-02,  2.4179e-02,  5.6716e-02,  7.6655e-02, -2.1965e-02,\n",
      "        -4.8634e-02,  3.0208e-02,  7.2449e-02,  6.8476e-02,  5.8555e-02,\n",
      "        -3.0515e-02,  6.7724e-02, -4.8277e-02, -2.2832e-03, -6.3427e-02,\n",
      "        -6.1940e-02, -6.4492e-02, -6.0731e-02, -7.4796e-02, -7.8220e-02,\n",
      "         5.2512e-02,  3.1165e-02, -2.1345e-02,  6.3537e-03,  7.0736e-02,\n",
      "         7.5888e-02, -6.4738e-03,  6.8858e-02,  3.8921e-03,  2.2686e-02,\n",
      "        -5.6137e-02,  6.3031e-02, -6.1965e-02,  7.9666e-02,  3.5303e-02,\n",
      "        -1.6973e-02, -1.9540e-02,  5.6967e-02, -1.4104e-02,  8.0944e-03,\n",
      "        -5.3716e-02, -5.0301e-02,  3.9708e-02,  2.4456e-02, -2.7292e-02,\n",
      "        -2.7298e-02, -5.5182e-02,  1.5874e-02,  6.4612e-02,  5.8159e-02,\n",
      "        -7.7585e-02,  6.4911e-02,  6.2700e-02,  5.5678e-02, -5.7749e-02,\n",
      "        -1.8618e-02,  7.8779e-02,  9.0088e-03, -6.7187e-02, -3.9860e-02,\n",
      "         4.0029e-02, -7.4751e-02, -1.5823e-02, -3.0046e-02, -4.6054e-02,\n",
      "        -6.0022e-03,  2.4743e-02, -6.8989e-02,  4.6382e-02,  3.5723e-02,\n",
      "        -3.2332e-02,  3.5670e-02, -7.0169e-02,  1.9620e-02,  4.1948e-02,\n",
      "         1.1083e-02,  2.2405e-02,  2.8669e-02,  6.2428e-02, -7.7695e-02,\n",
      "         1.4979e-02,  6.1248e-02, -7.1765e-02,  7.6439e-03, -2.7956e-02,\n",
      "         4.1780e-02,  2.5862e-02,  5.0104e-02,  3.4585e-02,  3.5365e-02,\n",
      "         9.9061e-03,  2.1322e-02, -3.7987e-02,  4.4485e-02, -6.3503e-02,\n",
      "         6.8970e-02,  3.8895e-02,  2.9300e-02,  3.7432e-02, -9.9356e-03,\n",
      "         5.2423e-02, -2.7514e-02, -3.6775e-02, -6.8361e-02, -7.0956e-02,\n",
      "        -4.4908e-02,  1.0307e-02, -6.6020e-02, -2.6189e-02, -1.6490e-02,\n",
      "        -4.1387e-02,  6.8005e-02, -4.8672e-02, -4.4076e-03,  3.5272e-02,\n",
      "        -1.9190e-02, -2.7138e-02, -2.5722e-02,  2.5278e-02,  5.2735e-02,\n",
      "         6.9790e-02,  5.8218e-02,  1.6887e-02, -7.7630e-02, -3.6429e-02,\n",
      "         2.3796e-02, -7.6119e-02,  7.3790e-02,  4.1357e-02, -7.3143e-02,\n",
      "         3.4111e-02, -5.5567e-02,  5.2773e-02,  4.1513e-02, -3.5387e-02,\n",
      "         4.4703e-02, -2.5588e-02, -3.7622e-02,  6.3459e-02, -6.0317e-02,\n",
      "         2.1399e-02, -8.7479e-03, -2.6507e-02,  9.5854e-03,  2.6273e-02,\n",
      "         6.7946e-02,  7.8503e-02, -6.1985e-02, -5.8070e-04, -7.0453e-02,\n",
      "         4.2597e-02,  1.6270e-02,  5.5847e-03,  8.1352e-03, -3.6914e-02,\n",
      "         3.1279e-02,  7.6454e-02,  6.9055e-02, -2.1322e-03, -1.8039e-02,\n",
      "        -7.2393e-05,  1.1911e-03,  4.7097e-02, -1.4847e-02,  4.1843e-02,\n",
      "        -2.6482e-02, -4.2018e-02,  5.7820e-02, -1.3293e-02, -1.6944e-02,\n",
      "        -7.6378e-02,  2.4433e-02, -2.6447e-02, -1.1732e-02, -2.4163e-02,\n",
      "         5.1748e-02, -4.4695e-02, -1.4084e-02, -7.9515e-02, -4.6248e-02,\n",
      "        -3.5378e-02,  6.5249e-02,  5.8328e-02,  7.2333e-02,  1.7921e-02,\n",
      "         1.2576e-03, -4.9213e-02,  4.1528e-03,  5.9715e-02, -4.2216e-02,\n",
      "         3.7819e-03], device='cuda:0')\n",
      "tensor([ 0.0651,  0.0542,  0.0409,  0.0380,  0.0618,  0.0073, -0.0088,  0.0191,\n",
      "        -0.0181, -0.0792, -0.0179,  0.0562, -0.0246,  0.0036,  0.0501,  0.0368,\n",
      "         0.0286,  0.0593, -0.0111, -0.0276, -0.0643,  0.0775, -0.0447,  0.0536,\n",
      "        -0.0682,  0.0578, -0.0443, -0.0679, -0.0154, -0.0219,  0.0705,  0.0398,\n",
      "         0.0500, -0.0727, -0.0031,  0.0297,  0.0722, -0.0210, -0.0219, -0.0060,\n",
      "         0.0713, -0.0047, -0.0534, -0.0031, -0.0400, -0.0441,  0.0227, -0.0235,\n",
      "        -0.0471, -0.0135,  0.0186, -0.0717, -0.0399, -0.0185,  0.0038, -0.0312,\n",
      "         0.0005,  0.0641, -0.0363, -0.0264,  0.0563,  0.0784, -0.0241,  0.0518,\n",
      "         0.0409, -0.0622, -0.0185,  0.0186,  0.0208,  0.0745, -0.0119,  0.0663,\n",
      "        -0.0687,  0.0394,  0.0618,  0.0029, -0.0465, -0.0499,  0.0652, -0.0265,\n",
      "         0.0087,  0.0269, -0.0376, -0.0049,  0.0232,  0.0593,  0.0637, -0.0198,\n",
      "        -0.0482,  0.0371,  0.0144, -0.0756, -0.0537, -0.0236, -0.0003,  0.0440,\n",
      "         0.0177, -0.0272,  0.0729, -0.0499,  0.0750,  0.0470, -0.0402,  0.0646,\n",
      "        -0.0710,  0.0294, -0.0650, -0.0321, -0.0586, -0.0211,  0.0600, -0.0579,\n",
      "         0.0096,  0.0005,  0.0687, -0.0517,  0.0148,  0.0288,  0.0430, -0.0514,\n",
      "         0.0042,  0.0789,  0.0739, -0.0560,  0.0446,  0.0141,  0.0380, -0.0247,\n",
      "         0.0664,  0.0353,  0.0373,  0.0642, -0.0137, -0.0565, -0.0596,  0.0136,\n",
      "         0.0770, -0.0381,  0.0676,  0.0414, -0.0493, -0.0127,  0.0054, -0.0350,\n",
      "        -0.0305,  0.0073, -0.0448, -0.0584,  0.0187,  0.0202, -0.0236, -0.0739,\n",
      "        -0.0735,  0.0577,  0.0701, -0.0015, -0.0471,  0.0235,  0.0490,  0.0375,\n",
      "         0.0631,  0.0732,  0.0274, -0.0499, -0.0255,  0.0504,  0.0460,  0.0263,\n",
      "         0.0050,  0.0452, -0.0707,  0.0737, -0.0638, -0.0659,  0.0696,  0.0400,\n",
      "        -0.0691,  0.0769, -0.0464,  0.0472, -0.0533,  0.0311, -0.0344,  0.0510,\n",
      "         0.0249,  0.0538, -0.0278, -0.0198, -0.0689,  0.0713, -0.0422, -0.0264,\n",
      "         0.0258, -0.0170, -0.0365,  0.0386, -0.0603, -0.0406, -0.0126,  0.0497,\n",
      "        -0.0585,  0.0448, -0.0047,  0.0320,  0.0745,  0.0152,  0.0495, -0.0042,\n",
      "        -0.0436,  0.0649,  0.0219,  0.0238, -0.0544, -0.0459,  0.0548, -0.0622,\n",
      "        -0.0010,  0.0225,  0.0498, -0.0226,  0.0772, -0.0482, -0.0054, -0.0776,\n",
      "        -0.0384,  0.0054,  0.0016,  0.0478, -0.0749, -0.0333, -0.0532,  0.0697,\n",
      "         0.0004, -0.0099, -0.0387,  0.0118, -0.0127, -0.0640, -0.0612, -0.0678,\n",
      "         0.0412, -0.0685,  0.0210, -0.0103,  0.0385,  0.0180,  0.0648,  0.0645,\n",
      "         0.0397, -0.0324, -0.0365,  0.0598,  0.0676, -0.0518,  0.0667,  0.0593],\n",
      "       device='cuda:0')\n",
      "tensor([[ 7.3790e-02, -1.1623e-02, -5.0504e-02,  ...,  4.0028e-02,\n",
      "          6.1882e-02,  1.4936e-02],\n",
      "        [-6.1325e-03, -3.2933e-03, -6.8482e-02,  ...,  3.7753e-03,\n",
      "          6.9547e-02, -7.8522e-02],\n",
      "        [ 7.6349e-02, -6.9417e-02, -1.8132e-02,  ..., -6.9990e-02,\n",
      "         -3.1533e-02, -6.6002e-02],\n",
      "        ...,\n",
      "        [-5.0297e-02, -1.7398e-02,  4.6229e-02,  ..., -3.2835e-02,\n",
      "         -6.0334e-02, -6.3362e-02],\n",
      "        [-3.6097e-02, -6.9456e-02,  4.2133e-05,  ..., -7.8837e-02,\n",
      "         -5.9723e-02, -2.3627e-02],\n",
      "        [ 3.2480e-02,  7.6611e-02,  6.8337e-02,  ...,  6.5163e-02,\n",
      "         -3.3487e-02,  2.5678e-02]], device='cuda:0')\n",
      "tensor([[ 1.8469e-02,  5.1143e-02, -3.3345e-02,  ...,  2.0635e-02,\n",
      "         -8.0730e-03, -2.6189e-02],\n",
      "        [ 1.0686e-02, -5.9765e-02, -2.1008e-03,  ...,  4.7714e-02,\n",
      "         -7.5284e-02, -2.9746e-02],\n",
      "        [ 4.5144e-02, -2.3036e-02,  2.5326e-02,  ..., -4.2055e-02,\n",
      "         -4.8998e-02, -7.2193e-05],\n",
      "        ...,\n",
      "        [-3.8618e-02, -1.6412e-02, -5.3832e-02,  ..., -2.0481e-02,\n",
      "          6.5510e-02, -2.9442e-03],\n",
      "        [ 2.1147e-03, -4.8537e-02,  7.4784e-02,  ...,  6.2505e-02,\n",
      "          2.9351e-02,  2.5015e-02],\n",
      "        [ 1.2462e-02,  4.2825e-02, -1.1076e-02,  ...,  6.2664e-02,\n",
      "         -3.5225e-02,  7.0767e-02]], device='cuda:0')\n",
      "tensor([[ 0.0521,  0.0795,  0.0469,  ...,  0.0706, -0.0373, -0.0788],\n",
      "        [-0.0370, -0.0640, -0.0587,  ..., -0.0084, -0.0691, -0.0057],\n",
      "        [-0.0592,  0.0477, -0.0284,  ...,  0.0477,  0.0669,  0.0762],\n",
      "        ...,\n",
      "        [-0.0141, -0.0379,  0.0695,  ..., -0.0402, -0.0720,  0.0195],\n",
      "        [ 0.0204, -0.0500,  0.0363,  ...,  0.0498, -0.0164,  0.0732],\n",
      "        [ 0.0371,  0.0165, -0.0705,  ..., -0.0752, -0.0621,  0.0282]],\n",
      "       device='cuda:0')\n",
      "tensor([ 4.3490e-02, -2.9778e-02, -6.5631e-02,  7.3509e-02,  4.6021e-02,\n",
      "         7.5584e-02, -6.6483e-04, -2.7983e-02, -1.2049e-02, -5.6541e-02,\n",
      "         7.2249e-02, -6.6314e-03,  2.4864e-02,  7.6937e-02, -5.8024e-02,\n",
      "        -6.4696e-02,  2.1960e-02, -2.4867e-02, -2.9820e-02,  3.1028e-02,\n",
      "         1.7857e-02, -7.9132e-02,  4.8939e-02, -1.4234e-03, -7.2073e-02,\n",
      "        -2.1675e-02, -4.9204e-02,  4.0504e-02,  6.2099e-02, -7.3710e-02,\n",
      "        -7.0499e-02,  2.4872e-02, -2.2447e-04,  2.1776e-02, -3.5887e-02,\n",
      "        -9.5647e-03,  7.7275e-03, -2.7000e-02,  7.9430e-02, -4.2841e-02,\n",
      "        -7.6870e-02,  1.1200e-02,  3.1612e-02,  3.5050e-02, -6.5787e-02,\n",
      "         1.7122e-02, -2.3870e-02,  5.1614e-02, -6.3859e-02, -5.1180e-02,\n",
      "         3.1269e-02, -4.4167e-02,  6.4504e-02,  6.2063e-02,  2.8312e-02,\n",
      "         2.3397e-02,  7.8947e-02,  5.3394e-02,  3.7772e-02,  6.5172e-02,\n",
      "         3.0708e-02, -7.2589e-02, -1.2717e-02,  6.7809e-02,  1.7953e-03,\n",
      "        -7.0195e-02, -5.8376e-02,  2.4553e-03, -3.8497e-02,  2.9948e-02,\n",
      "         5.6968e-02,  2.4898e-02, -6.9111e-02,  6.2830e-02, -1.5070e-02,\n",
      "         2.0617e-02,  2.5960e-02, -6.4522e-03,  1.1872e-02,  1.3906e-02,\n",
      "        -5.3555e-02,  3.8541e-02,  2.8609e-02,  5.0836e-02,  1.2369e-02,\n",
      "         8.1275e-03,  1.2276e-02, -6.1229e-03,  3.1279e-02,  5.0405e-02,\n",
      "        -5.3525e-02,  5.5661e-02, -6.1563e-02,  6.4993e-02, -3.5759e-02,\n",
      "         2.1493e-02,  2.7039e-02,  5.0997e-02,  9.6796e-03, -1.6378e-02,\n",
      "         3.6769e-02,  3.5059e-02, -4.6135e-02, -2.2649e-03, -7.9614e-02,\n",
      "         2.0333e-02, -4.3642e-02,  2.2778e-02, -3.7758e-02, -6.0622e-02,\n",
      "         3.3204e-02, -5.8283e-02, -1.2161e-02, -5.1321e-02, -6.9591e-02,\n",
      "         3.3074e-02,  1.4465e-02, -4.9910e-02, -7.8411e-02, -3.8300e-02,\n",
      "         2.2476e-02,  1.1168e-03,  2.8589e-03,  9.0650e-03, -6.7250e-02,\n",
      "         2.8564e-02, -1.3903e-02,  1.9749e-02, -1.6018e-02, -7.1561e-02,\n",
      "        -7.6000e-02, -2.0764e-02,  3.0042e-02, -7.2260e-02, -8.5550e-03,\n",
      "        -1.6958e-02, -1.0935e-02,  7.2465e-03,  2.0817e-02, -1.2808e-02,\n",
      "        -2.1174e-02,  7.3957e-02,  3.1255e-02,  4.9098e-02,  5.2393e-02,\n",
      "        -3.7080e-02, -6.4192e-02, -5.4936e-02,  5.9070e-02, -3.9431e-02,\n",
      "        -6.0390e-02,  5.0560e-02, -9.9198e-03,  3.3962e-02, -5.6569e-02,\n",
      "        -4.4296e-02, -3.7824e-02,  1.3899e-02,  9.6472e-03,  4.7351e-02,\n",
      "        -2.3338e-02,  4.5157e-02,  6.2423e-02, -8.2534e-03, -3.4875e-02,\n",
      "        -5.8736e-02, -6.4172e-02,  1.2967e-03,  4.1559e-02,  8.2700e-04,\n",
      "         2.1334e-02, -6.3481e-02, -2.5125e-02, -1.8673e-02, -3.2901e-02,\n",
      "        -3.0706e-03,  3.6278e-02, -1.7483e-02,  1.6810e-02,  3.4224e-02,\n",
      "         4.4482e-02,  3.0182e-02,  6.9208e-02,  6.8673e-02, -2.0266e-02,\n",
      "         2.6680e-02,  1.7785e-02,  6.7142e-02, -5.6703e-02,  4.6813e-02,\n",
      "        -4.4901e-02, -3.5127e-02,  4.4070e-02,  5.3358e-02,  6.5565e-02,\n",
      "         2.1619e-02,  2.7635e-02,  5.2736e-02,  2.1378e-02, -2.3710e-02,\n",
      "         1.5182e-02,  3.3190e-02, -3.5303e-02,  1.2967e-02,  7.1196e-02,\n",
      "        -1.2091e-04,  7.5304e-03, -1.8755e-02,  2.4747e-02,  7.5602e-02,\n",
      "        -1.7877e-03, -3.2432e-02,  1.9706e-02, -6.1369e-03, -4.7620e-02,\n",
      "         4.7361e-02,  2.3738e-02,  5.4067e-02,  6.6604e-02, -2.1422e-02,\n",
      "        -2.8334e-02, -1.0359e-02, -2.3381e-02, -2.5236e-02,  3.5925e-02,\n",
      "         4.2936e-02, -3.8278e-02, -7.9257e-03,  4.6511e-02,  7.0083e-02,\n",
      "         3.8802e-02,  1.3395e-02, -6.5184e-02, -1.3576e-02,  1.0963e-02,\n",
      "         6.6600e-02,  1.1426e-02,  2.0059e-02, -1.0916e-02, -4.7063e-02,\n",
      "        -3.2941e-02,  2.7479e-02,  4.2548e-02, -5.0340e-02, -3.7642e-03,\n",
      "         2.4925e-02, -2.8088e-02, -1.2878e-02,  3.6340e-02,  7.1475e-02,\n",
      "         7.6048e-02,  7.2160e-02,  6.4259e-02,  1.1819e-02, -7.5359e-02,\n",
      "        -4.4308e-05], device='cuda:0')\n",
      "tensor([-0.0131, -0.0372,  0.0087,  0.0560,  0.0681, -0.0501,  0.0366,  0.0472,\n",
      "        -0.0419,  0.0223,  0.0376,  0.0109,  0.0091, -0.0072,  0.0588,  0.0713,\n",
      "        -0.0293, -0.0747,  0.0763, -0.0337, -0.0065, -0.0089, -0.0469, -0.0510,\n",
      "         0.0714, -0.0258, -0.0042, -0.0346, -0.0282, -0.0181, -0.0126, -0.0719,\n",
      "        -0.0321,  0.0336, -0.0615,  0.0338,  0.0640, -0.0534,  0.0372, -0.0505,\n",
      "        -0.0506, -0.0109, -0.0536, -0.0010,  0.0630, -0.0361,  0.0699,  0.0529,\n",
      "        -0.0554,  0.0044, -0.0213,  0.0689, -0.0692, -0.0075, -0.0377,  0.0612,\n",
      "        -0.0404,  0.0235,  0.0668, -0.0761, -0.0646,  0.0375, -0.0130, -0.0083,\n",
      "        -0.0445,  0.0519,  0.0449, -0.0230,  0.0473,  0.0279,  0.0652, -0.0037,\n",
      "        -0.0477,  0.0644,  0.0682, -0.0328, -0.0632,  0.0152, -0.0641, -0.0787,\n",
      "        -0.0297,  0.0002, -0.0032, -0.0005, -0.0551,  0.0567, -0.0586, -0.0114,\n",
      "        -0.0479,  0.0496,  0.0524, -0.0409,  0.0186, -0.0573,  0.0301,  0.0451,\n",
      "         0.0218, -0.0044,  0.0568,  0.0222,  0.0706, -0.0602, -0.0722,  0.0423,\n",
      "        -0.0503, -0.0381,  0.0363,  0.0162, -0.0753, -0.0641,  0.0211, -0.0441,\n",
      "         0.0107,  0.0485,  0.0534, -0.0555, -0.0077, -0.0580,  0.0563,  0.0388,\n",
      "         0.0306, -0.0459,  0.0265,  0.0379, -0.0561, -0.0770,  0.0505,  0.0793,\n",
      "        -0.0493, -0.0324, -0.0364, -0.0059,  0.0794, -0.0296,  0.0352,  0.0029,\n",
      "        -0.0388, -0.0140, -0.0116, -0.0667, -0.0589,  0.0722,  0.0553, -0.0540,\n",
      "        -0.0587, -0.0030, -0.0426,  0.0122, -0.0608,  0.0429,  0.0798, -0.0759,\n",
      "        -0.0445, -0.0585,  0.0543, -0.0272,  0.0369, -0.0312,  0.0093,  0.0471,\n",
      "        -0.0428, -0.0188, -0.0556, -0.0198,  0.0458,  0.0630, -0.0765, -0.0497,\n",
      "         0.0707, -0.0447, -0.0516,  0.0642, -0.0357, -0.0275, -0.0370,  0.0435,\n",
      "        -0.0163, -0.0061,  0.0775, -0.0026,  0.0776,  0.0662,  0.0081,  0.0450,\n",
      "         0.0722, -0.0196,  0.0486, -0.0503,  0.0672,  0.0529,  0.0542, -0.0302,\n",
      "        -0.0222, -0.0560,  0.0207, -0.0563, -0.0110,  0.0151,  0.0214, -0.0079,\n",
      "        -0.0021,  0.0518, -0.0088,  0.0257, -0.0610,  0.0351,  0.0399, -0.0168,\n",
      "        -0.0777, -0.0231,  0.0331, -0.0560, -0.0433,  0.0611, -0.0278,  0.0170,\n",
      "         0.0009, -0.0080, -0.0306, -0.0498, -0.0485, -0.0671, -0.0285, -0.0749,\n",
      "        -0.0319,  0.0153, -0.0221, -0.0581, -0.0773,  0.0716, -0.0505, -0.0024,\n",
      "        -0.0701,  0.0769, -0.0142, -0.0404, -0.0161, -0.0156,  0.0737,  0.0060,\n",
      "         0.0189,  0.0744, -0.0044, -0.0746, -0.0060, -0.0505,  0.0512,  0.0243,\n",
      "         0.0179,  0.0125, -0.0032,  0.0334, -0.0460, -0.0320,  0.0107, -0.0479],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.0066, -0.0513, -0.0240,  ..., -0.0678, -0.0379,  0.0724],\n",
      "        [ 0.0257, -0.0232, -0.0235,  ...,  0.0209, -0.0267,  0.0624],\n",
      "        [-0.0285, -0.0039, -0.0778,  ..., -0.0483,  0.0767, -0.0059],\n",
      "        ...,\n",
      "        [ 0.0104,  0.0092, -0.0369,  ...,  0.0444, -0.0062,  0.0098],\n",
      "        [-0.0191,  0.0442, -0.0499,  ...,  0.0621,  0.0502, -0.0331],\n",
      "        [ 0.0106,  0.0461, -0.0426,  ...,  0.0117,  0.0608, -0.0334]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for i,p in enumerate(model.parameters()):\n",
    "    print(p.data)\n",
    "    p.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr = 1e-04)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, clip):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for i, batch in enumerate(iterator):\n",
    "        src = batch.src\n",
    "        trg = batch.trg\n",
    "        optimizer.zero_grad()\n",
    "        output = model(src, trg)\n",
    "        #trg = [trg len, batch size]\n",
    "        #output = [trg len, batch size, output dim]\n",
    "\n",
    "        output_dim = output.shape[-1]\n",
    "        output = output[1:].view(-1, output_dim)\n",
    "        trg = trg[1:].view(-1)\n",
    "        #trg = [(trg len - 1) * batch size]\n",
    "        #output = [(trg len - 1) * batch size, output dim]\n",
    "\n",
    "        loss = criterion(output, trg)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(iterator):\n",
    "            src = batch.src\n",
    "            trg = batch.trg\n",
    "            output = model(src, trg, 0) #turn off teacher forcing\n",
    "            #trg = [trg len, batch size]\n",
    "            #output = [trg len, batch size, output dim]\n",
    "\n",
    "            output_dim = output.shape[-1]\n",
    "            output = output[1:].view(-1, output_dim)\n",
    "            trg = trg[1:].view(-1)\n",
    "            #trg = [(trg len - 1) * batch size]\n",
    "            #output = [(trg len - 1) * batch size, output dim]\n",
    "\n",
    "            loss = criterion(output, trg)\n",
    "            epoch_loss += loss.item()  \n",
    "            \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5a50cc42bf64e2e8abbfabb4cbc4590",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9236f1cc2dc4410f84c42b70fe4193d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  1 | Time: 17m 30s\n",
      "\tTrain Loss: 8.733 | Train PPL: 6204.231\n",
      "\t Val. Loss: 8.731 |  Val. PPL: 6189.712\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "095c6a8b036d4dd287de706aaa6ddac0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "N_EPOCHS = 30\n",
    "CLIP = 1\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "last_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
    "    valid_loss = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss <= best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'tut1-model_med.pt')\n",
    "        \n",
    "    if last_valid_loss <= valid_loss:\n",
    "        break\n",
    "        \n",
    "    last_valid_loss = valid_loss    \n",
    "    \n",
    "    print(f'Epoch: {epoch+1:2} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(586779, 64)\n",
       "    (rnn): LSTM(64, 64, dropout=0.5)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embedding): Embedding(70797, 64)\n",
       "    (rnn): LSTM(64, 64, dropout=0.5)\n",
       "    (fc_out): Linear(in_features=64, out_features=70797, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('tut1-model.pt',  map_location=torch.device(\"cuda\")),strict=False)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_sentence(sentence, src_field, trg_field, model, device, max_len = 30):\n",
    "    model.eval()\n",
    "    tokens = [src_field.init_token] + sentence + [src_field.eos_token]\n",
    "    src_indexes = [src_field.vocab.stoi[token] for token in tokens]\n",
    "    #print(src_indexes)\n",
    "    src_tensor = torch.tensor(src_indexes).unsqueeze(1).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        hidden, cell = model.encoder(src_tensor)\n",
    "    trg_indexes = [trg_field.vocab.stoi[trg_field.init_token]]\n",
    "\n",
    "    for i in range(max_len):\n",
    "        trg_tensor = torch.tensor([trg_indexes[-1]]).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output, hidden, cell = model.decoder(trg_tensor, hidden, cell)\n",
    "\n",
    "        pred_token = output.argmax(1).item()\n",
    "        trg_indexes.append(pred_token)\n",
    "\n",
    "        if pred_token == trg_field.vocab.stoi[trg_field.eos_token]:\n",
    "            break\n",
    "\n",
    "    trg_tokens = [trg_field.vocab.itos[i] for i in trg_indexes]\n",
    "    \n",
    "    if trg_tokens[-1] == trg_field.eos_token : \n",
    "        trg_tokens = trg_tokens[:-1]\n",
    "\n",
    "    return trg_tokens[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src = ['端午', '節', '將', '至', '，', '不少', '糖尿病', '友會', '詢問', '營養師', '能否', '吃', '粽子', '。', '答案', '是', '肯定', '的', '，', '只要', '謹記', '適量', '攝取', '且', '把握', '低油', '、', '低鹽', '、', '低糖', '、', '高纖', '與', '均衡', '飲食', '的', '原', '則', '，', '仍', '可', '和', '家人', '共享', '端午', '美食', '與', '佳節', '氣氛', '。', '童綜合', '醫院', '營養', '治療', '科營', '養師', '黃筱尹', '表示', '，', '傳統', '粽子', '主要', '以', '糯米', '為主', '材料', '再', '搭配', '其他', '食材', '（', '如', '栗子', '、', '蛋黃', '、', '滷肉', '、', '花生', '等', '）', '一同', '包覆', '而成', '，', '而', '糯米', '屬全', '榖根', '莖類', '食物', '，', '因此', '需注意', '食用', '的', '份量', '，', '否則', '易使', '血糖', '上升', '。', '一', '顆', '鹹', '粽約', '含', '一碗', '飯', '，', '鹼粽', '則', '有', '半碗', '飯', '，', '食用', '時', '可', '選擇', '中型', '粽子', '，', '或', '將', '其', '納入', '飲食', '計畫', '中', '並', '與', '米飯', '做', '代換', '，', '這', '樣可減', '少額', '外醣類', '攝取', '。', '近年', '養生', '風氣', '盛行', '，', '業者', '紛紛', '推出', '雜糧養', '生粽', '、', '健康', '全', '榖粽', '等', '，', '製程', '上', '強調', '少油', '、', '少鹽', '與', '高纖', '，', '這', '對', '於', '糖尿病', '友是', '另', '一', '項', '選擇', '。', '食用', '時', '注意', '食材', '中', '是否', '有', '栗子', '、', '蓮子', '、', '山藥', '、', '薏仁', '、', '紅豆', '或', '綠豆', '等', '。', '這', '些', '食材', '雖', '富含', '高纖', '但', '仍', '屬全', '榖根', '莖類', '食物', '，', '只要', '謹守', '不', '過量', '攝取', '的', '原', '則', '，', '糖尿病', '友', '仍', '可', '享受', '健康', '創', '意粽', '的', '美味', '。', '黃筱尹', '建議', '，', '除', '糖尿病', '患者', '外', '，', '一般', '民眾', '吃', '粽', '也', '需注意', '，', '糯米', '不易', '消化', '，', '對於', '胃腸', '功能', '不佳', '者易', '造成', '胃脹', '、', '胃痛', '，', '細嚼', '慢嚥', '與', '適量', '攝取', '可', '減少', '腸胃不適', '的', '症狀', '。']\n",
      "trg = ['掌握', '三', '低', '一', '高', '，', '糖尿病患', '安心', '吃', '粽']\n"
     ]
    }
   ],
   "source": [
    "example_idx = 100\n",
    "\n",
    "src = vars(test_data.examples[example_idx])['src']\n",
    "trg = vars(test_data.examples[example_idx])['trg']\n",
    "\n",
    "print(f'src = {src}')\n",
    "print(f'trg = {trg}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15693\n",
      "10848\n",
      "10848\n",
      "10848\n",
      "10848\n",
      "10848\n",
      "10848\n",
      "57112\n",
      "57112\n",
      "57112\n",
      "57112\n",
      "57112\n",
      "57112\n",
      "44845\n",
      "10848\n",
      "predicted trg = ['場館', '辯護', '辯護', '辯護', '辯護', '辯護', '辯護', '餡料', '餡料', '餡料', '餡料', '餡料', '餡料', '公布稅', '辯護']\n"
     ]
    }
   ],
   "source": [
    "summarization = summarize_sentence(src, SRC, TRG, model, device)\n",
    "\n",
    "print(f'predicted trg = {summarization}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('system_summaries_seq2seq.txt', 'w', encoding = 'utf-8')\n",
    "for i in range(49297):\n",
    "    src = vars(test_data.examples[i])['src']\n",
    "    #trg = vars(test_data.examples[i])['trg']\n",
    "    file.write(''.join(summarize_sentence(src, SRC, TRG, model, device)))\n",
    "    file.write('\\n')\n",
    "    if i % 1000 == 0:\n",
    "        print(i)\n",
    "file.close()    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}